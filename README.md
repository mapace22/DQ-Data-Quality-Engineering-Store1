# üõ†Ô∏è Data Quality & Engineering Pipeline: Store 1 Customer Data

## üéØ Visi√≥n General
Este proyecto establece un **Framework de Calidad de Datos** para "Store 1", enfocado en la transformaci√≥n de datos brutos e inconsistentes en un formato estandarizado y "listo para el an√°lisis". El objetivo central fue construir un pipeline robusto que garantice la integridad de los datos mediante protocolos automatizados de validaci√≥n.

## üß± Implementaci√≥n T√©cnica
El pipeline aborda problemas cr√≠ticos de calidad de datos utilizando **Python**, con un enfoque en la escalabilidad y la resiliencia ante errores.

### Funcionalidades de Ingenier√≠a:
* **Normalizaci√≥n Automatizada:** Implementaci√≥n de algoritmos de manipulaci√≥n de cadenas (`strip`, `replace`, `split`) para eliminar ruido y estandarizar identificadores de usuario y categor√≠as de productos.
* **Integridad de Tipos de Datos:** Conversi√≥n sistem√°tica de tipos de datos (ej. flotantes a enteros para m√©tricas de edad) para asegurar la consistencia matem√°tica en procesos posteriores.
* **Manejo Robustos de Errores:** Integraci√≥n de bloques `try-except` para gestionar anomal√≠as en los inputs de datos brutos, evitando fallos del pipeline durante el procesamiento por lotes.
* **Procesamiento por Lotes (Batch Processing):** Desarrollo de l√≥gica iterativa para aplicar est√°ndares de limpieza de forma eficiente en todo el dataset de clientes.

## üìä L√≥gica del Pipeline (ETL)
1.  **Evaluaci√≥n (Assessment):** Identificaci√≥n de inconsistencias estructurales en `user_id`, `user_name`, y `user_age`.
2.  **Limpieza (Cleaning):** Eliminaci√≥n de artefactos de formato y normalizaci√≥n de capitalizaci√≥n (case normalization) para datos categ√≥ricos.
3.  **Validaci√≥n:** Aplicaci√≥n de l√≥gica de negocio para asegurar que los valores num√©ricos se encuentren dentro de los rangos operativos esperados.
4.  **S√≠ntesis:** Generaci√≥n de m√©tricas clave (gasto total, m√≠nimo y m√°ximo) por perfil de usuario.

## üõ†Ô∏è Stack Tecnol√≥gico
* **Lenguaje:** Python 3.12.1
* **L√≥gica Central:** Estructuras de datos din√°micas, manejo de excepciones y m√©todos avanzados de strings.
* **Entorno:** Jupyter Notebook / VS Code.

## üí° Impacto de Datos
Mediante la implementaci√≥n de este pipeline, se logr√≥ transicionar de datos fragmentados a una **"√önica Fuente de Verdad" (Single Source of Truth)**. Esto garantiza que cualquier modelo predictivo o reporte financiero posterior se base en datos de alta fidelidad, eliminando sesgos operativos.
